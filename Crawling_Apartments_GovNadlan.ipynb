{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a310879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "from collections import defaultdict\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484cb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_page(URL):\n",
    "    SCROLL_PAUSE_TIME = 3\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(URL)\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    i = 0\n",
    "    while i<300:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        i = i + 1\n",
    "        last_height = new_height\n",
    "    return driver.page_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2292b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawlHTML(htmlText):    \n",
    "    soup = BeautifulSoup(htmlText, \"html.parser\")\n",
    "    i=0\n",
    "    dic = {}\n",
    "    list1 = []\n",
    "    for t in soup.findAll(class_=\"tableTitles\"):\n",
    "        if i == 1:\n",
    "            break\n",
    "        i = i + 1\n",
    "        for f in t.findAll(\"button\"):            \n",
    "            dic[f[\"aria-label\"]] = []\n",
    "    df=pd.DataFrame(dic)\n",
    "    for t in soup.findAll(class_=\"tableRow\"):\n",
    "        for f in t.findAll(class_=\"tableCol\"):\n",
    "            k = f.find(\"div\")             \n",
    "            if k is not None:\n",
    "                list1.append(k.text.strip())\n",
    "            else:\n",
    "                list1.append(\"\")\n",
    "        list1.pop()\n",
    "        df.loc[len(df)] = list1\n",
    "        list1 = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37211c",
   "metadata": {},
   "source": [
    "Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7681adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col_from_df(df):\n",
    "    df.drop(columns =['','מגמת שינוי','גוש חלקה - תת חלקה','סוג נכס'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51260eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(df,name):\n",
    "    headerList = ['Date', 'Address', 'Rooms', 'Floor', 'Square', 'Price']\n",
    "    df.to_csv(name,header=headerList, index=False, encoding = \"ISO-8859-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "UrlRovaBet = \"https://www.nadlan.gov.il/?search=%D7%A8%D7%95%D7%91%D7%A2%20%D7%91%20%D7%90%D7%A9%D7%93%D7%95%D7%93\"\n",
    "UrlRovaDaled = \"https://www.nadlan.gov.il/?search=%D7%90%D7%A9%D7%93%D7%95%D7%93%20%D7%A8%D7%95%D7%91%D7%A2%20%D7%93\"\n",
    "UrlRovaYudAlef = \"https://www.nadlan.gov.il/?search=%D7%90%D7%A9%D7%93%D7%95%D7%93%20%D7%A8%D7%95%D7%91%D7%A2%20%D7%99%22%D7%90\"\n",
    "UrlRovaVav = \"https://www.nadlan.gov.il/?search=%D7%90%D7%A9%D7%93%D7%95%D7%93%20%D7%A8%D7%95%D7%91%D7%A2%20%D7%95\"\n",
    "\n",
    "listOfUrl = [UrlRovaBet,UrlRovaDaled,UrlRovaYudAlef,UrlRovaVav]\n",
    "listNameOfCsv = [\"rovaBet.csv\",\"rovaDaled.csv\",\"rovaYudAlef.csv\", \"rovaVav.csv\"]\n",
    "\n",
    "for url,name in zip(listOfUrl,listNameOfCsv):    \n",
    "    html = scroll_page(url)\n",
    "    df = crawlHTML(html)\n",
    "    drop_col_from_df(df)\n",
    "    save_csv(df,name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
